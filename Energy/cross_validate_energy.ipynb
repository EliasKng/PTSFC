{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Energy.HelpFunctions.get_energy_data import get_energy_data, prepare_data\n",
    "from HelpFunctions.date_and_time import most_recent_thursday, split_time\n",
    "from Energy.Models.baseline import baseline\n",
    "from HelpFunctions.calc_score import evaluate_horizon\n",
    "from HelpFunctions.mix_models import mix_models\n",
    "from Energy.Models.Model1 import model1\n",
    "from Energy.Models.Model2 import model2\n",
    "from Energy.Models.Model4_population import model4_population\n",
    "from Energy.Models.Model4 import model4\n",
    "from Energy.Models.Model3 import model3\n",
    "from Energy.Models.Model5 import model5\n",
    "from Energy.Models.Model4_holidays_2 import model4_holidays_2\n",
    "from Energy.Models.Model4_sunhours import model4_sunhours\n",
    "# import importlib\n",
    "# importlib.reload(Energy.Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If needed: Fetch energy-data first"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "473173c9a1c4423e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from Energy.HelpFunctions.get_energy_data import fetch_energy_data\n",
    "# fetch_energy_data()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2a8b259e2c6f3ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_energy_data()\n",
    "df = prepare_data(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bbe30845c7abb4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validate baseline model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58741ff6badc9818"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove everything til last thursday night 12pm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c75bc49e7d3d4f25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_date_excl = most_recent_thursday(df)\n",
    "df_cval = df.loc[df.index < start_date_excl]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "393b23d7490e8cb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeatedly run the model. Record predictions and true values (observations). Make sure the observations are available for the most recent prediction."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b8dbeb69e58ff51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from HelpFunctions.mix_models import mix_models\n",
    "\n",
    "\n",
    "def evaluate_models(models, df, last_x, years =False, months=False, weeks=False):\n",
    "    # Check that exactly one of the boolean parameters is True\n",
    "    if sum([years, months, weeks]) != 1:\n",
    "        raise ValueError(\"Exactly one of the boolean parameters (years, months, weeks) must be True.\")\n",
    "    \n",
    "    years = int(years)\n",
    "    months = int(months)\n",
    "    weeks = int(weeks)\n",
    "        \n",
    "    for m in models:\n",
    "        print(f'*********** Start the evaluation of Model {m[\"name\"]} ***********')\n",
    "        m['evaluation'] = evaluate_model(m, df, last_x, years, months, weeks)\n",
    "        \n",
    "def evaluate_model(model, df, last_x, years, months, weeks):\n",
    "    df_before = df\n",
    "    evaluation = pd.DataFrame()\n",
    "    \n",
    "    for w in range(last_x):\n",
    "        print(f'Iteration {w} of {last_x}')\n",
    "        df_before, df_after = split_time(df_before, num_years=years, num_months=months, num_weeks=weeks)        \n",
    "        \n",
    "        pred = None     \n",
    "        # Is mixed model?\n",
    "        if callable(model['function']):\n",
    "            pred = model['function'](df_before)\n",
    "        else:\n",
    "            pred = mix_models(model['function'][0], model['function'][1], df_before)\n",
    "               \n",
    "        \n",
    "        obs = pd.DataFrame({'gesamt': df.loc[pred['forecast_date']][\"gesamt\"]})\n",
    "        pred = pred.set_index('forecast_date')\n",
    "        merged_df = pd.merge(pred, obs, left_index=True, right_index=True) \n",
    "    \n",
    "    \n",
    "         # Add scores to the merged_df\n",
    "        for index, row in merged_df.iterrows():\n",
    "            quantile_preds = row[['q0.025','q0.25','q0.5','q0.75','q0.975']]\n",
    "            observation = row['gesamt']\n",
    "            score = evaluate_horizon(quantile_preds, observation)\n",
    "            merged_df.at[index, 'score'] = score\n",
    "        # print(merged_df[['q0.025','q0.25','q0.5','q0.75','q0.975']])\n",
    "        evaluation = pd.concat([evaluation, merged_df])\n",
    "    return evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59605ee6165a131"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation of selected Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76ab5ca11aa99bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Energy.Models import mstl\n",
    "import importlib\n",
    "importlib.reload(mstl)\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    # {\n",
    "    #     'name': 'mixed',\n",
    "    #     'function': [[model4_sunhours, model4_holidays_2, model4_population],[1,1,1]]\n",
    "    # },\n",
    "    {\n",
    "        'name': 'MM mstl bl model5',\n",
    "        'function': [[mstl.mstl, model5, baseline],[1,1,1]]\n",
    "    },\n",
    "    {\n",
    "        'name': 'MM bl model5',\n",
    "        'function': [[model5, baseline],[1,1]]\n",
    "    },\n",
    "    {\n",
    "        'name': 'MM mstl model5',\n",
    "        'function': [[mstl.mstl, model5],[1,1]]\n",
    "    },\n",
    "    # {\n",
    "    #     'name': 'model5',\n",
    "    #     'function': model5\n",
    "    # },\n",
    "    # {\n",
    "    #     'name': 'baseline',\n",
    "    #     'function': baseline\n",
    "    #  },\n",
    "    # {\n",
    "    #     'name': 'mstl',\n",
    "    #     'function': mstl.mstl\n",
    "    #  },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d73ef814183cf22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_models(models, df_cval, last_x=10, weeks=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb47d8a3d2534a75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save evaluations in pkl file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eba78bf2f16f3ea6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with open('./Model evaluations/mm_m5_bl_m4_x.pkl', 'wb') as f:\n",
    "#     pickle.dump(models, f)\n",
    "\n",
    "# with open('./Model evaluations/m4_pop_m5.pkl', 'rb') as f:\n",
    "#     models2 = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75464ad22c6250a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a table that only contains the different scores of the different models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abdceae11f001180"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "horizons = ['36 hour', '40 hour', '44 hour', '60 hour', '64 hour', '68 hour']\n",
    "scores = []\n",
    "names = []\n",
    "for h in horizons:\n",
    "    for m in models:\n",
    "        col_name = f'{m[\"name\"]}: {h}'\n",
    "        scores.append(m['evaluation']['score'][m['evaluation']['horizon'] == h])\n",
    "        names.append(col_name)\n",
    "\n",
    "score_df = pd.concat(scores, axis=1,keys=names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6e3c0acfdcdacb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot the densities of the obtained scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bb45a13bfa8a60a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# models_display = ['baseline', 'mstl', 'model5', 'MM mstl bl model5', 'MM mstl bl model5']\n",
    "models_display = ['MM mstl bl model5', 'MM bl model5','MM mstl model5']\n",
    "# models_display = ['baseline', 'model4_sunhours', 'model4_holidays_2', 'model4', 'model4_population']\n",
    "for h in [str(h) + \" hour\" for h in [36, 40, 44, 60, 64, 68]]:\n",
    "    # sns.kdeplot(data=score_df.loc[:,[f'baseline: {h}',f'model3: {h}',f'MM_baseline_model3: {h}']], fill=True)\n",
    "    sns.kdeplot(data=score_df.loc[:,[f'{m}: {h}' for m in models_display]], fill=True)\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Density Plot of Scores: {h} horizon')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.savefig(f'plots/density_plot_{h.replace(\" \", \"_\")}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d666e6ed0e246e75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for h in [str(h) + \" hour\" for h in [36, 40, 44, 60, 64, 68]]:\n",
    "    # Plot values from two columns over time\n",
    "    score_df_36_no_na = score_df[score_df[f'{models_display[0]}: {h}'].notna()]\n",
    "    for c in [f'{m}: {h}' for m in models_display]:\n",
    "        # plt.plot(score_df_36_no_na.index, score_df_36_no_na['baseline: 36 hour'], label='baseline')\n",
    "        # plt.plot(score_df_36_no_na.index, score_df_36_no_na['model1: 36 hour'], label='model1')\n",
    "        # plt.plot(score_df_36_no_na.index, score_df_36_no_na['model2: 36 hour'], label='model2')\n",
    "        plt.plot(score_df_36_no_na.index, score_df_36_no_na[c], label=c)\n",
    "        # plt.plot(score_df_36_no_na.index, score_df_36_no_na[c], label='model4')\n",
    "        # Adding labels and title\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('score')\n",
    "    plt.title(f'Comparison of scores over time: {h}')\n",
    "    plt.ylim(0,50)\n",
    "    \n",
    "    # Display legend\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/line_plot_{h.replace(\" \", \"_\")}.png')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3700136a69248829"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Whole evaluation for a model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c86e2d49eb70198"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[m['name'] for m in models]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d2b07cd0734e2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_evaluation(evaluation_data):\n",
    "    # Assuming your DataFrame is named df\n",
    "    numeric_columns = evaluation_data.select_dtypes(include='number')\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for column in numeric_columns.columns:\n",
    "        plt.plot(evaluation_data.index, evaluation_data[column], label=column)\n",
    "    \n",
    "    # Adding labels and legend\n",
    "    plt.xlabel('Forecast Date')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Line Plot for Numeric Columns')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'plots/evaluation_overview.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_evaluation(models[1]['evaluation'][models[1]['evaluation']['horizon'] == '36 hour'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97760d7c13d97324"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Search for outliers (highest scores per horizon)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "621e615bdcb76d6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_display = ['model4_holidays_2']\n",
    "horizons = [36]\n",
    "for h in [str(h) + \" hour\" for h in [36, 40, 44, 60, 64, 68]]:\n",
    "    for c in [f'{m}: {h}' for m in models_display]:\n",
    "        df_sorted = score_df[c].sort_values().dropna().tail(10)\n",
    "        \n",
    "        \n",
    "        print(f'{c}')\n",
    "        print(df_sorted)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9921d7965cd06b0b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[m['name'] for m in models]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b0d508e9dd18925"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models[5]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac4f7143efeacbf5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1f13521e77045c7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
