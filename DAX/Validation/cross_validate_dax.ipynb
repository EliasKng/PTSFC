{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:27:53.407841Z",
     "start_time": "2023-11-18T14:27:53.398220Z"
    }
   },
   "outputs": [],
   "source": [
    "from HelpFunctions.date_and_time import most_recent_thursday, split_time\n",
    "from DAX.HelpFunctions.get_dax_data import get_dax_data\n",
    "from datetime import timedelta\n",
    "from HelpFunctions.calc_score import evaluate_horizon\n",
    "import pandas as pd\n",
    "from DAX.Models.baseline import baseline\n",
    "import pickle\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(Energy.Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_dax_data()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4540cd020c8925b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We have to start with the tuesday data\n",
    "start_date_excl = most_recent_thursday(df) - timedelta(days=1)\n",
    "df_cval = df.loc[df.index < start_date_excl]\n",
    "df_cval.index = df_cval.index.date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a2d4f5c5f31fd76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cval.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6b11a2aa69c0249"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def evaluate_models(models, df, last_x, years =False, months=False, weeks=False):\n",
    "    # Check that exactly one of the boolean parameters is True\n",
    "    if sum([years, months, weeks]) != 1:\n",
    "        raise ValueError(\"Exactly one of the boolean parameters (years, months, weeks) must be True.\")\n",
    "    \n",
    "    years = int(years)\n",
    "    months = int(months)\n",
    "    weeks = int(weeks)\n",
    "        \n",
    "    for m in models:\n",
    "        print(f'*********** Start the evaluation of Model {m[\"name\"]} ***********')\n",
    "        m['evaluation'] = evaluate_model(m, df, last_x, years, months, weeks)\n",
    "        \n",
    "def evaluate_model(model, df, last_x, years, months, weeks):\n",
    "    df_before = df\n",
    "    evaluation = pd.DataFrame()\n",
    "    \n",
    "    for w in range(last_x):\n",
    "        print(f'Iteration {w} of {last_x}')\n",
    "        df_before, df_after = split_time(df_before, num_years=years, num_months=months, num_weeks=weeks)\n",
    "        pred = model['function'](df_before)\n",
    "        obs = pd.DataFrame({'ret1': df.loc[pred['forecast_date']]['ret1']})\n",
    "        obs.index = obs.index.strftime('%Y-%m-%d')\n",
    "        pred = pred.set_index('forecast_date')\n",
    "        merged_df = pd.merge(pred, obs, left_index=True, right_index=True) \n",
    "    \n",
    "         # Add scores to the merged_df\n",
    "        for index, row in merged_df.iterrows():\n",
    "            quantile_preds = row[['q0.025','q0.25','q0.5','q0.75','q0.975']]\n",
    "            observation = row['ret1']\n",
    "            score = evaluate_horizon(quantile_preds, observation)\n",
    "            merged_df.at[index, 'score'] = score\n",
    "        # print(merged_df[['q0.025','q0.25','q0.5','q0.75','q0.975']])\n",
    "        evaluation = pd.concat([evaluation, merged_df])\n",
    "    return evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:27:38.648383Z",
     "start_time": "2023-11-18T14:27:38.638771Z"
    }
   },
   "id": "9ad542f046842a66"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'baseline',\n",
    "        'function': baseline\n",
    "     },\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:27:39.160593Z",
     "start_time": "2023-11-18T14:27:39.155321Z"
    }
   },
   "id": "13fbb2ee46633091"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Start the evaluation of Model baseline ***********\n",
      "Iteration 0 of 10\n",
      "Iteration 1 of 10\n",
      "Iteration 2 of 10\n",
      "Iteration 3 of 10\n",
      "Iteration 4 of 10\n",
      "Iteration 5 of 10\n",
      "Iteration 6 of 10\n",
      "Iteration 7 of 10\n",
      "Iteration 8 of 10\n",
      "Iteration 9 of 10\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models, df, 10, weeks=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:27:40.385590Z",
     "start_time": "2023-11-18T14:27:40.241288Z"
    }
   },
   "id": "b92eb089f837ede7"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "with open('./Model evaluations/baseline.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "#         \n",
    "# with open('./Model evaluations/baseline.pkl', 'rb') as f:\n",
    "#     models = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:28:45.245198Z",
     "start_time": "2023-11-18T14:28:45.231718Z"
    }
   },
   "id": "df953c81258d61db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30bef563aae17557"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
