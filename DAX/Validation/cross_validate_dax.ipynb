{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from HelpFunctions.date_and_time import most_recent_thursday, split_time\n",
    "from DAX.HelpFunctions.get_dax_data import get_dax_data\n",
    "from datetime import timedelta\n",
    "from HelpFunctions.calc_score import evaluate_horizon\n",
    "import pandas as pd\n",
    "from DAX.Models.baseline import baseline\n",
    "from HelpFunctions.mix_models import mix_models\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import importlib\n",
    "# importlib.reload(Energy.Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_dax_data()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4540cd020c8925b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We have to start with the tuesday data\n",
    "start_date_excl = most_recent_thursday(df) - timedelta(days=1)\n",
    "df_cval = df.loc[df.index < start_date_excl]\n",
    "df_cval.index = df_cval.index.date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a2d4f5c5f31fd76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cval.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6b11a2aa69c0249"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_models(models, df, last_x, years =False, months=False, weeks=False):\n",
    "    # Check that exactly one of the boolean parameters is True\n",
    "    if sum([years, months, weeks]) != 1:\n",
    "        raise ValueError(\"Exactly one of the boolean parameters (years, months, weeks) must be True.\")\n",
    "    \n",
    "    years = int(years)\n",
    "    months = int(months)\n",
    "    weeks = int(weeks)\n",
    "        \n",
    "    for m in models:\n",
    "        print(f'*********** Start the evaluation of Model {m[\"name\"]} ***********')\n",
    "        m['evaluation'] = evaluate_model(m, df, last_x, years, months, weeks)\n",
    "        \n",
    "def evaluate_model(model, df, last_x, years, months, weeks):\n",
    "    df_before = df\n",
    "    evaluation = pd.DataFrame()\n",
    "    \n",
    "    for w in range(last_x):\n",
    "        print(f'Iteration {w+1} of {last_x}')\n",
    "        df_before, df_after = split_time(df_before, num_years=years, num_months=months, num_weeks=weeks)\n",
    "        \n",
    "        pred = None\n",
    "        # Is mixed model?\n",
    "        if callable(model['function']):\n",
    "            pred = model['function'](df_before)\n",
    "        else: \n",
    "            pred = mix_models(model['function'][0], model['function'][1], df_before)\n",
    "        # Makes sure we try to find observations for dates that have an observation (e.g. 05-01 is missing)\n",
    "        dates = [[horizon+1, d] for horizon,d in enumerate(pred['forecast_date']) if d in df.index]\n",
    "        pred = pred.set_index('forecast_date')\n",
    "\n",
    "        \n",
    "        # Add observations to pred\n",
    "        pred['observation'] = ''\n",
    "        pred['score'] = ''\n",
    "        for h,d in dates:\n",
    "            # Look up the right observation for date d\n",
    "            o = df.loc[d][f'ret{h}']\n",
    "            pred.loc[d,'observation'] = o\n",
    "    \n",
    "        # Add scores to pred\n",
    "        for index, row in pred.iterrows():\n",
    "            quantile_preds = row[['q0.025','q0.25','q0.5','q0.75','q0.975']]\n",
    "            observation = row['observation']\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(f'Obs: :{observation}:')\n",
    "            print(type(observation))\n",
    "            score = evaluate_horizon(quantile_preds, observation)\n",
    "            \n",
    "            pred.at[index, 'score'] = score\n",
    "            \n",
    "        evaluation = pd.concat([evaluation, pred])\n",
    "    evaluation = evaluation.sort_index()\n",
    "    \n",
    "    return evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad542f046842a66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from DAX.Models.garch11_t import garch11_t\n",
    "from DAX.Models.garch11 import garch11\n",
    "from DAX.Models.baseline_100 import baseline_100\n",
    "from DAX.Models.baseline_300 import baseline_300\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'baseline',\n",
    "        'function': baseline\n",
    "     },\n",
    "    {\n",
    "        'name': 'garch11',\n",
    "        'function': garch11\n",
    "     },\n",
    "    # {\n",
    "    #     'name': 'garch11_t',\n",
    "    #     'function': garch11_t\n",
    "    #  },\n",
    "    {\n",
    "        'name': 'baseline_garch11',\n",
    "        'function': [[baseline, garch11],[0.5,0.5]]\n",
    "     },\n",
    "    # {\n",
    "    #     'name': 'baseline_300',\n",
    "    #     'function': baseline_300\n",
    "    #  },\n",
    "    # {\n",
    "    #     'name': 'baseline_100',\n",
    "    #     'function': baseline_100\n",
    "    #  },\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13fbb2ee46633091"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_models(models, df, 100, weeks=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b92eb089f837ede7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('./Model evaluations/BL_GARCH11_MM-BL-GARCH11.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "#         \n",
    "# with open('./Model evaluations/baseline.pkl', 'rb') as f:\n",
    "#     models = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df953c81258d61db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models[0]['evaluation']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1b61a6549ba0d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "horizons = [str(i) + \" day\" for i in (1, 2, 5, 6, 7)]\n",
    "scores = []\n",
    "names = []\n",
    "for m in models:\n",
    "    scores_m = m['evaluation'].loc[:,('horizon','score')]\n",
    "    names.append(f'horizon_{m[\"name\"]}')\n",
    "    names.append(m[\"name\"])\n",
    "    scores.append(scores_m)\n",
    "\n",
    "score_df = pd.concat(scores, axis=1)\n",
    "score_df.columns = names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed8a405ad11008d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b6f9b4ca9dc47f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63db63d24be5d7b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for horizon in [str(i) + \" day\" for i in (1, 2, 5, 6, 7)]:\n",
    "    filtered_df = score_df[score_df['horizon_garch11'] == horizon]\n",
    "    # sns.kdeplot(data=filtered_df['baseline'], fill=True, label='Baseline')\n",
    "    sns.kdeplot(data=filtered_df['garch11'], fill=True, label='Garch(1,1)')\n",
    "    sns.kdeplot(data=filtered_df['baseline_garch11'], fill=True, label='Mixed')\n",
    "    # sns.kdeplot(data=filtered_df['baseline_300'], fill=True, label='Baseline 300')\n",
    "    \n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Density Plot of Scores: {horizon}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # plt.xlim(0,8)\n",
    "    # Display the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dd817437bf1dc92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for horizon in [str(i) + \" day\" for i in (1, 2, 5, 6, 7)]:\n",
    "    filtered_df = score_df[score_df['horizon_garch11'] == horizon]\n",
    "\n",
    "    # Plot values from two columns over time\n",
    "    # filtered_df = filtered_df[score_df['garch11'].notna()]\n",
    "    # plt.plot(score_df_36_no_na.index, score_df_36_no_na['baseline: 36 hour'], label='baseline')\n",
    "    # plt.plot(filtered_df.index, filtered_df['baseline'], label='baseline')\n",
    "    # plt.plot(score_df_36_no_na.index, score_df_36_no_na['model2: 36 hour'], label='model2')\n",
    "    plt.plot(filtered_df.index, filtered_df['garch11'], label='garch11')\n",
    "    plt.plot(filtered_df.index, filtered_df['baseline_garch11'], label='mixed')\n",
    "    # plt.plot(filtered_df.index, filtered_df['garch11_t'], label='garch11_t')\n",
    "    \n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('score')\n",
    "    plt.title('Comparison of scores over time')\n",
    "    \n",
    "    # Display legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e2680ed6f75645"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "56144364d68040c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
